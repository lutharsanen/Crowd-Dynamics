{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that you have the following installed on your machine to view interactive plots in jupyter lab\n",
    "# https://github.com/matplotlib/ipympl#installation\n",
    "# run \n",
    "#pip install ipympl\n",
    "#jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "#jupyter lab build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(rows, cols, R):\n",
    "\n",
    "    # dummy array to easily loop over coordinates\n",
    "    agents = np.zeros((rows, cols))\n",
    "    \n",
    "    # for each agent store the distances to all other nodes\n",
    "    distances = np.zeros((rows, cols, rows, cols))\n",
    "\n",
    "    for i1, agent1 in np.ndenumerate(agents):\n",
    "        x_coord_self = i1[1]\n",
    "        y_coord_self = i1[0]\n",
    "\n",
    "        for i2, agent2 in np.ndenumerate(agents):\n",
    "            x_coord_1 = i2[1]\n",
    "            x_coord_2 = i2[1]-cols\n",
    "            y_coord = i2[0]\n",
    "\n",
    "            distance_1 = np.sqrt((x_coord_1 - x_coord_self)**2 + (y_coord - y_coord_self)**2)\n",
    "            distance_2 = np.sqrt((x_coord_2 - x_coord_self)**2 + (y_coord - y_coord_self)**2)\n",
    "            distances[y_coord_self][x_coord_self][y_coord][x_coord_1] = np.min([distance_1,distance_2])\n",
    "    \n",
    "    # print(distances[2][1])\n",
    "\n",
    "\n",
    "    # for each agent store the angle to all of its neighbors\n",
    "    angles = np.zeros((rows, cols, rows, cols))\n",
    "\n",
    "    for i1, agent1 in np.ndenumerate(agents):\n",
    "        x_coord_self = i1[1]\n",
    "        y_coord_self = i1[0]\n",
    "\n",
    "        for i2, agent2 in np.ndenumerate(agents):\n",
    "            x_coord_1 = i2[1]\n",
    "            x_coord_2 = i2[1]-cols\n",
    "            \n",
    "            if x_coord_2 <= -cols/2+1:\n",
    "                x_coord = x_coord_1\n",
    "            else:\n",
    "                x_coord = x_coord_2\n",
    "            y_coord = i2[0]\n",
    "\n",
    "            vec_1 = (1, 0)\n",
    "            vec_2 = (x_coord - x_coord_self, y_coord - y_coord_self)\n",
    "\n",
    "            c = np.dot(vec_1, vec_2)/np.linalg.norm(vec_1)/np.linalg.norm(vec_2) # -> cosine of the angle\n",
    "            angle = np.arccos(np.clip(c, -1, 1)) # if you really want the angle\n",
    "            \n",
    "            angles[y_coord_self][x_coord_self][y_coord][x_coord_1] = angle\n",
    "    \n",
    "    # print(angles[2][1])\n",
    "\n",
    "\n",
    "    # for each agent store the impact (weight) that all other nodes have on it.\n",
    "    weights = np.zeros((rows, cols, rows, cols))\n",
    "\n",
    "    for i1, agent1 in np.ndenumerate(agents):\n",
    "        x_coord_self = i1[1]\n",
    "        y_coord_self = i1[0]\n",
    "\n",
    "        for i2, agent2 in np.ndenumerate(agents):\n",
    "            x_coord = i2[1]\n",
    "            y_coord = i2[0]\n",
    "\n",
    "            distance = distances[y_coord_self][x_coord_self][y_coord][x_coord]\n",
    "            angle = angles[y_coord_self][x_coord_self][y_coord][x_coord]\n",
    "\n",
    "            weight = np.exp(- distance / R) * (1 + w + (1 - w) * np.cos(np.pi - angle))\n",
    "\n",
    "            if distance > 3*R or distance < 0:\n",
    "                weight = 0\n",
    "\n",
    "            weights[y_coord_self][x_coord_self][y_coord][x_coord] = weight\n",
    "\n",
    "        # normalize the weights so that the sum is equal to 1\n",
    "        # before we can sum up all the weights for each agent, we have to make sure that there is no more nan in the data. nan was always the agent in focus, so it should be 0 that the agent does not influence himself.\n",
    "        weights[np.isnan(weights)] = 0\n",
    "        # K is normalizing factor\n",
    "        K = np.sum(weights[y_coord_self][x_coord_self])\n",
    "        weights[y_coord_self][x_coord_self] = np.divide(weights[y_coord_self][x_coord_self], K)\n",
    "        \n",
    "        \n",
    "    # print(weights[2][1])\n",
    "    \n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_next_state(agents, weights):\n",
    "    \n",
    "    # loop over all agents and calcualte the weighted amount of people in active state that impact this agent\n",
    "    for i1, agent1 in np.ndenumerate(agents):\n",
    "        \n",
    "        x_coord_self = i1[1]\n",
    "        y_coord_self = i1[0]\n",
    "        \n",
    "        weights_agents = weights[y_coord_self, x_coord_self]\n",
    "    \n",
    "        state = agent1['state']\n",
    "        substate = agent1['substate']\n",
    "        threshold = agent1['threshold']\n",
    "        \n",
    "        if state == 1:\n",
    "            if substate < 2:\n",
    "                agent1['substate'] += 1\n",
    "            else:\n",
    "                agent1['next_state'] = 2\n",
    "                agent1['substate'] = 0\n",
    "        \n",
    "        elif state == 2:\n",
    "            if substate < 2:\n",
    "                agent1['substate'] += 1\n",
    "            else:\n",
    "                agent1['next_state'] = 0\n",
    "                agent1['substate'] = 0\n",
    "                \n",
    "        else:\n",
    "            # current state: 0 (inactive)\n",
    "            # calculate the probability that he becomes active\n",
    "            active_agents_weight = 0\n",
    "            \n",
    "            for i2, agent2 in np.ndenumerate(agents):\n",
    "                x_coord = i2[1]\n",
    "                y_coord = i2[0]\n",
    "                \n",
    "                # sum over all the agents in the radius that have an influence on the agent in question\n",
    "                if agent2['state'] == 1:\n",
    "                    weight = weights_agents[y_coord, x_coord]\n",
    "                    active_agents_weight += weight\n",
    "        \n",
    "            \n",
    "            if active_agents_weight > threshold:\n",
    "                # update agent to be in active state\n",
    "                agent1['next_state'] = 1\n",
    "                agent1['substate'] = 0\n",
    "\n",
    "                \n",
    "def update_state(agents):\n",
    "    for i, agent in np.ndenumerate(agents):\n",
    "        agent['state'] = agent['next_state']\n",
    "        \n",
    "        \n",
    "def get_na(agents,rows, cols):\n",
    "    res_aggregate = np.zeros(cols)\n",
    "    res_state_only = np.zeros((rows, cols))\n",
    "\n",
    "    # sum all cols up\n",
    "    for index, agent in np.ndenumerate(agents):\n",
    "        y_coord = index[0]\n",
    "        x_coord = index[1]\n",
    "        state = agent['state']\n",
    "\n",
    "        res_state_only[y_coord][x_coord] = state\n",
    "\n",
    "        if state == 1:\n",
    "            res_aggregate[x_coord] += 1\n",
    "    return res_aggregate, res_state_only\n",
    "\n",
    "def get_a_max(res_aggregate):\n",
    "    return np.amax(res_aggregate, axis=1)\n",
    "        \n",
    "def run_simulation(agents, weights, rows, cols, threshold, size_triggering_group, time_steps):\n",
    "    \n",
    "    # N_a(t)\n",
    "    res_aggregate_total = []\n",
    "    res_state_only_total = []\n",
    "\n",
    "    # initialise thresholds and states\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            agents[i][j]['state'] = 0\n",
    "            agents[i][j]['substate'] = 0\n",
    "            agents[i][j]['next_state'] = 0\n",
    "            agents[i][j]['threshold'] = np.random.uniform(threshold - 0.05, threshold + 0.05)\n",
    "\n",
    "    agents_in_row = size_triggering_group[0]\n",
    "    agents_in_col = size_triggering_group[1]\n",
    "    \n",
    "    for i in range(agents_in_row):\n",
    "        for j in range(agents_in_col):\n",
    "            agents[i + (int((rows - agents_in_col) / 2))][j+3]['state'] = 1\n",
    "            agents[i + (int((rows - agents_in_col) / 2))][j+3]['next_state'] = 1\n",
    "    \n",
    "    res_aggregate, res_state_only = get_na(agents, rows, cols)\n",
    "    \n",
    "    res_aggregate_total.append(res_aggregate)\n",
    "    res_state_only_total.append(res_state_only)\n",
    "    \n",
    "    for i in range(time_steps):\n",
    "        res_aggregate = np.zeros(cols)\n",
    "        res_state_only = np.zeros((rows, cols))\n",
    "        \n",
    "        # sum all cols up\n",
    "        for index, agent in np.ndenumerate(agents):\n",
    "            y_coord = index[0]\n",
    "            x_coord = index[1]\n",
    "            state = agent['state']\n",
    "            \n",
    "            res_state_only[y_coord][x_coord] = state\n",
    "            \n",
    "            if state == 1:\n",
    "                res_aggregate[x_coord] += 1\n",
    "                \n",
    "        set_next_state(agents, weights)\n",
    "        \n",
    "        # update all agents synchronously\n",
    "        update_state(agents)\n",
    "        \n",
    "        res_aggregate, res_state_only = get_na(agents, rows, cols)\n",
    "        \n",
    "        res_aggregate_total.append(res_aggregate)\n",
    "        res_state_only_total.append(res_state_only)\n",
    "        \n",
    "    return res_state_only_total, res_aggregate_total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dario/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "rows = 25\n",
    "cols = 75\n",
    "\n",
    "R = 2\n",
    "# factor of how much more people to the right of a person have an influence compared to the people on the left\n",
    "w = 0.25\n",
    "\n",
    "# weights can be pre calculated as they won't change during simulation\n",
    "weights = calculate_weights(rows, cols, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e510741c1812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0magents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'substate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'next_state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'threshold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_triggering_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0ma_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_a_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-11bf2b2ec2c4>\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(agents, weights, rows, cols, threshold, size_triggering_group, time_steps)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mres_aggregate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_coord\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mset_next_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# update all agents synchronously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-11bf2b2ec2c4>\u001b[0m in \u001b[0;36mset_next_state\u001b[0;34m(agents, weights)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mactive_agents_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndenumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mx_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0my_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/index_tricks.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \"\"\"\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# threshold for each agent to become active, will be randomly chosen in the interval +-0.05\n",
    "thresholds = [.25, .26, .27, .28, .29, .3, .31, .32]\n",
    "# fraction of people on the two most left columns that intitiate the wave\n",
    "size_triggering_groups = [(1,2), (2,2), (2,3), (3,3), (3,4), (4,4)]\n",
    "\n",
    "time_steps = 50\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(i, res, colax):\n",
    "    colax.set_data(res[i])\n",
    "    return colax\n",
    "\n",
    "a_max_mean = np.zeros((len(thresholds), len(size_triggering_groups)))\n",
    "a_max_std = np.zeros((len(thresholds), len(size_triggering_groups)))\n",
    "\n",
    "for i1, threshold in enumerate(thresholds):\n",
    "    \n",
    "    for i2, size_triggering_group in enumerate(size_triggering_groups):\n",
    "        \n",
    "        a_max_temp_mean = []\n",
    "        a_max_temp_std = []\n",
    "\n",
    "        for i in range(15):\n",
    "            # each agent has one the following states\n",
    "            # 0: inactive\n",
    "            # 1: active\n",
    "            # 2: refracter\n",
    "            agents = np.zeros((rows, cols), dtype=[('state', np.int), ('substate', np.int), ('next_state', np.int), ('threshold', np.float)])\n",
    "\n",
    "            results = run_simulation(agents, weights, rows, cols, threshold, size_triggering_group, time_steps)\n",
    "            a_max = get_a_max(results[1])\n",
    "            a_max_temp_mean.append(np.mean(a_max))\n",
    "            a_max_temp_std.append(np.std(a_max))\n",
    "           \n",
    "            # initialize the plot (each color 0,1,2 is represented once so that the colors are also there for the next frames in the animation)\n",
    "            initial = np.zeros((rows, cols))\n",
    "            initial[0][1] = 1\n",
    "            initial[0][2] = 2\n",
    "            cax = ax.matshow(initial)\n",
    "            \n",
    "            # call the animator\n",
    "            # blit=True means only re-draw the parts that have changed\n",
    "            anim = animation.FuncAnimation(fig, animate, fargs=(results[0], cax), frames=len(results[0]))\n",
    "            #writers.reset_available_writers()\n",
    "\n",
    "            # On windows/linux make sure to have ffmpeg installed before running this cell\n",
    "            # https://ffmpeg.org/\n",
    "            # on a mac you can simply use brew to install: brew install ffmpeg\n",
    "            anim.save('animations/laOla-' + str(threshold) + '-' + str(size_triggering_group[0] * size_triggering_group[1]) + '-version' + str(i) +'.mp4', writer=\"ffmpeg\", fps=5)\n",
    "        \n",
    "        mean_of_a_max_temp_mean = np.mean(a_max_temp_mean)\n",
    "        mean_of_a_max_temp_std = np.mean(a_max_temp_std)\n",
    "        print(threshold, size_triggering_group, 'Avg of A(t):', mean_of_a_max_temp_mean, 'Std of A(t)', mean_of_a_max_temp_std)\n",
    "        a_max_mean[i1][i2] = mean_of_a_max_temp_mean\n",
    "        a_max_std[i1][i2] = mean_of_a_max_temp_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('a_max_mean.npy', a_max_mean)\n",
    "np.save('a_max_std.npy', a_max_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "threshold_plot = [[threshold] * len(size_triggering_groups) for threshold in thresholds]\n",
    "triggering_groups_plot = [group[0] * group[1] for group in size_triggering_groups] * len(thresholds)\n",
    "\n",
    "fig = plt.figure() \n",
    "wf = fig.add_subplot(111, projection='3d') \n",
    "\n",
    "wf.plot_wireframe(triggering_groups_plot, threshold_plot, a_max_mean, rstride=1, cstride=1) \n",
    "plt.safefig('result_plot_mean.pdf')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "threshold_plot = [[threshold] * len(size_triggering_groups) for threshold in thresholds]\n",
    "triggering_groups_plot = [group[0] * group[1] for group in size_triggering_groups] * len(thresholds)\n",
    "\n",
    "fig = plt.figure() \n",
    "wf = fig.add_subplot(111, projection='3d') \n",
    "\n",
    "wf.plot_wireframe(triggering_groups_plot, threshold_plot, a_max_std, rstride=1, cstride=1) \n",
    "plt.safefig('result_plot_std.pdf')\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
